{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a Husband: Using explainable AI to define male mosquito flight differences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy import signal, stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn import metrics\n",
    "import tqdm\n",
    "\n",
    "np.random.seed(0)\n",
    "sys.path.append('H:/Documents/PhD/mosquito-swarms/anomalies-in-swarming/src')\n",
    "\n",
    "import reading\n",
    "import preprocessing\n",
    "import features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males, couples = reading.load_all_files()\n",
    "\n",
    "males = preprocessing.remove_low_length_tracks(males)\n",
    "couples = preprocessing.remove_low_length_tracks(couples)\n",
    "\n",
    "\n",
    "def add_velocity(dataset):\n",
    "    count = 0\n",
    "    for trial_index, trial in enumerate(dataset):\n",
    "        for track_index, track in enumerate(trial):\n",
    "            x_dot, y_dot, z_dot = preprocessing.velocity(track)\n",
    "            dataset[trial_index][track_index][:, 3] = np.append(x_dot, [np.nan,np.nan])\n",
    "            dataset[trial_index][track_index][:, 4] = np.append(y_dot, [np.nan,np.nan])\n",
    "            dataset[trial_index][track_index][:, 5] = np.append(z_dot, [np.nan,np.nan])\n",
    "            count += 1 \n",
    "    return dataset\n",
    "\n",
    "males = add_velocity(males)\n",
    "couples = add_velocity(couples)\n",
    "\n",
    "\n",
    "df = pd.read_excel('H:/Documents/PhD/mosquito-swarms/anomalies-in-swarming/data/search-to-pursuit/data.ods')\n",
    "\n",
    "f = df[df['id'] == 'F']\n",
    "fm = df[df['id'] == 'FM']\n",
    "\n",
    "def format(df):\n",
    "    trials = []\n",
    "    for trial in df['seq'].unique():\n",
    "        tracks = []\n",
    "        for mossie_id in df[df['seq'] == trial]['mqid'].unique():\n",
    "            tracks.append(\n",
    "                df[df['seq'] == trial][df['mqid'] == mossie_id][['p1','p2','p3']].values\n",
    "                )\n",
    "        trials.append(tracks)\n",
    "    return trials\n",
    "\n",
    "f_df = format(f)\n",
    "fm_df = format(fm)\n",
    "\n",
    "count = 0\n",
    "for trial_index, trial in enumerate(f_df):\n",
    "    for track_index, track in enumerate(trial):\n",
    "        f_df[trial_index][track_index] = preprocessing.append_vel(track)\n",
    "        count += 1 \n",
    "\n",
    "count = 0\n",
    "for trial_index, trial in enumerate(fm_df):\n",
    "    for track_index, track in enumerate(trial):\n",
    "        fm_df[trial_index][track_index] = preprocessing.append_vel(track)\n",
    "        count += 1 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''REMOVE TRIAL ID 5'''\n",
    "\n",
    "males.pop(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Seperating tracks using a sliding window method'''\n",
    "\n",
    "def window(track, size, over_lap):        \n",
    "    start = 0\n",
    "    end = size\n",
    "    tracks = []\n",
    "    while end < len(track):\n",
    "        tracks.append(\n",
    "            track[start:end]\n",
    "        )\n",
    "        start += (size - over_lap)\n",
    "        end += (size - over_lap)\n",
    "    return tracks\n",
    "\n",
    "def segment_tracks(dataset, size, over_lap):\n",
    "    split_dataset = []\n",
    "    trial_id = 0\n",
    "    while trial_id < len(dataset):\n",
    "        track_id = 0\n",
    "        trial = []\n",
    "        while track_id < len(dataset[trial_id]):\n",
    "            if len(dataset[trial_id][track_id]) > size:\n",
    "                w = window(dataset[trial_id][track_id], size, over_lap)\n",
    "                if len(w) > 1:\n",
    "                    trial.append(w)\n",
    "            track_id += 1\n",
    "        trial_id += 1\n",
    "        split_dataset.append(trial)\n",
    "    return split_dataset\n",
    "\n",
    "\n",
    "SIZE = 40\n",
    "OVER_LAP = 20\n",
    "\n",
    "split_males = segment_tracks(males, SIZE, OVER_LAP)\n",
    "split_couples = segment_tracks(couples, SIZE, OVER_LAP)\n",
    "split_females = segment_tracks(f_df, SIZE, OVER_LAP)\n",
    "split_focal_males = segment_tracks(fm_df, SIZE, OVER_LAP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(dataset):\n",
    "    trial_id = 0\n",
    "    while trial_id < len(dataset):\n",
    "        track_group = 0\n",
    "        while track_group < len(dataset[trial_id]):\n",
    "            track_id = 0\n",
    "            while track_id < len(dataset[trial_id][track_group]):\n",
    "                # Angular Velocity \n",
    "                av_1 = features.angular_velocity(dataset[trial_id][track_group][track_id], (0,1,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(av_1, [np.nan, np.nan]), axis=1)\n",
    "                \n",
    "                av_2 = features.angular_velocity(dataset[trial_id][track_group][track_id], (0,1), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(av_2, [np.nan, np.nan]), axis=1)\n",
    "                \n",
    "                av_3 = features.angular_velocity(dataset[trial_id][track_group][track_id], (1,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(av_3, [np.nan, np.nan]), axis=1)\n",
    "                \n",
    "                av_4 = features.angular_velocity(dataset[trial_id][track_group][track_id], (0,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(av_4, [np.nan, np.nan]), axis=1)\n",
    "                \n",
    "\n",
    "                # Angular Acceleration \n",
    "                aa_1 = features.angular_acceleration(dataset[trial_id][track_group][track_id], (0,1,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(aa_1, [np.nan, np.nan, np.nan]), axis=1)\n",
    "                \n",
    "                aa_2 = features.angular_acceleration(dataset[trial_id][track_group][track_id], (0,1), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(aa_2, [np.nan, np.nan, np.nan]), axis=1)\n",
    "                \n",
    "                aa_3 = features.angular_acceleration(dataset[trial_id][track_group][track_id], (1,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(aa_3, [np.nan, np.nan, np.nan]), axis=1)\n",
    "\n",
    "                aa_4 = features.angular_acceleration(dataset[trial_id][track_group][track_id], (0,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(aa_4, [np.nan, np.nan, np.nan]), axis=1)\n",
    "\n",
    "                # Direction of Flight Change \n",
    "                dof_1 = features.direction_of_flight_change(dataset[trial_id][track_group][track_id], (0,1,2))\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(dof_1, [np.nan,np.nan]), axis=1)\n",
    "\n",
    "                # Centroid Distance Function\n",
    "                centroid_distance_function = features.centroid_distance_function(dataset[trial_id][track_group][track_id], (0,1,2))\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), centroid_distance_function, axis=1)\n",
    "\n",
    "                # Orthogonal Components \n",
    "                pv, tv, iv = features.orthogonal_components(dataset[trial_id][track_group][track_id], (0,1,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(pv, [np.nan, np.nan, np.nan]), axis=1)\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(tv, [np.nan, np.nan, np.nan]), axis=1)\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(iv, [np.nan, np.nan, np.nan]), axis=1)\n",
    "                \n",
    "                # Absolute radial velocity\n",
    "                radial_velocity = np.abs(features.velocity(dataset[trial_id][track_group][track_id], (0,1,2), time_step=(1/25), schema='central'))\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(radial_velocity, [np.nan, np.nan]), axis=1)\n",
    "\n",
    "                # Absolute radial acceleration\n",
    "                radial_acceleration = features.acceleration(dataset[trial_id][track_group][track_id], (0,1,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(radial_acceleration, [np.nan, np.nan, np.nan]), axis=1)\n",
    "\n",
    "                # Absolute radial jerk\n",
    "                jerk = features.jerk(dataset[trial_id][track_group][track_id], (0,1,2), time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(jerk, [np.nan, np.nan, np.nan, np.nan]), axis=1)\n",
    "\n",
    "                # X axial acceleration\n",
    "                x = features.axial_acceleration(dataset[trial_id][track_group][track_id], 0, time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(x, [np.nan, np.nan, np.nan]), axis=1)\n",
    "\n",
    "                # Y axial acceleration\n",
    "                y = features.axial_acceleration(dataset[trial_id][track_group][track_id], 1, time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(y, [np.nan, np.nan, np.nan]), axis=1)\n",
    "\n",
    "                # Z axial acceleration\n",
    "                z = features.axial_acceleration(dataset[trial_id][track_group][track_id], 2, time_step=(1/25), schema='central')\n",
    "                dataset[trial_id][track_group][track_id] = np.insert(dataset[trial_id][track_group][track_id], len(dataset[trial_id][track_group][track_id][0]), np.append(z, [np.nan, np.nan, np.nan]), axis=1)\n",
    "\n",
    "                track_id += 1\n",
    "            track_group += 1\n",
    "        trial_id += 1\n",
    "\n",
    "    return dataset\n",
    "\n",
    "males = extract(split_males)\n",
    "couples = extract(split_couples)\n",
    "f_df = extract(split_females)\n",
    "fm_df = extract(split_focal_males)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Generate statistics of each metric from each position'''\n",
    "\n",
    "def track_stats(track, indexes, columns):\n",
    "    f_stats = dict()\n",
    "    for index, col in enumerate(columns):\n",
    "        elements = track[:, indexes[index]]\n",
    "        elements = elements[~np.isinf(elements)]\n",
    "        elements = elements[~np.isnan(elements)]\n",
    "        f_stats[col + ' (mean)'] = np.mean(elements)\n",
    "        f_stats[col + ' (median)'] = np.median(elements)\n",
    "        f_stats[col + ' (standard deviation)'] = np.std(elements)\n",
    "        f_stats[col + ' (kurtosis)'] = stats.kurtosis(elements)\n",
    "        f_stats[col + ' (skewness)'] = stats.skew(elements)\n",
    "        f_stats[col + ' (no of local minima)'] = signal.argrelextrema(elements, np.less)[0].shape[0]\n",
    "        f_stats[col + ' (no of local maxima)'] = signal.argrelextrema(elements, np.greater)[0].shape[0]\n",
    "        f_stats[col + ' (no of zero-crossings)'] = len(np.where(np.diff(np.sign(elements)))[0])\n",
    "        try:\n",
    "            f_stats[col + ' (1st quartile)'] = np.percentile(elements, 25)\n",
    "            f_stats[col + ' (3rd quartile)'] = np.percentile(elements, 75)\n",
    "        except:\n",
    "            f_stats[col + ' (1st quartile)'] = np.nan\n",
    "            f_stats[col + ' (3rd quartile)'] = np.nan\n",
    "\n",
    "    return f_stats\n",
    "\n",
    "\n",
    "def remove_nans(df):\n",
    "    columns_to_drop = df.columns.to_series()[np.isinf(df).any()]\n",
    "    for column in columns_to_drop:\n",
    "        df = df.drop(columns=str(column))\n",
    "\n",
    "    columns_to_drop = df.columns.to_series()[np.isnan(df).any()]\n",
    "    for column in columns_to_drop:\n",
    "        df = df.drop(columns=str(column))\n",
    "    \n",
    "    indexes = df[df.isna().any(axis=1)].index\n",
    "    df = df.drop(index=indexes)\n",
    "    return df\n",
    "\n",
    "\n",
    "def compute_segment_statistics(dictionary, dataset, indexes, feature_columns):\n",
    "    for trial in dataset:\n",
    "        for group in trial:\n",
    "            for track in group:\n",
    "                data = track_stats(track, indexes=indexes, columns=feature_columns)\n",
    "                for d in data:\n",
    "                    dictionary[d].append(data[d])\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def add_other_features(data, pos):\n",
    "    def stats(features):\n",
    "        return np.mean(features), np.std(features) \n",
    "\n",
    "    features_dict = {\n",
    "        'Straightness': [],\n",
    "        'Convex Hull (volume)': [],\n",
    "        'Convex Hull (surface area)': [],\n",
    "        'Curvature Scale Space (mean)': [],\n",
    "        'Curvature Scale Space (standard deviation)': [],\n",
    "        'Fractal Dimension': [],\n",
    "        'Curvature X-Y (mean)': [],\n",
    "        'Curvature X-Y (standard deviation)': [],\n",
    "        'Curvature Y-Z (mean)': [],\n",
    "        'Curvature Y-Z (standard deviation)': [],\n",
    "        'Curvature X-Z (mean)': [],\n",
    "        'Curvature X-Z (standard deviation)': [],\n",
    "    }\n",
    "\n",
    "    trial_id = 0\n",
    "    while trial_id < len(data):\n",
    "        track_group = 0\n",
    "        while track_group < len(data[trial_id]):\n",
    "            track_id = 0\n",
    "            while track_id < len(data[trial_id][track_group]):\n",
    "                features_dict['Straightness'].append(features.straightness(data[trial_id][track_group][track_id], pos))\n",
    "                features_dict['Convex Hull (volume)'].append(features.convex_hull_area(data[trial_id][track_group][track_id], pos))\n",
    "                features_dict['Convex Hull (surface area)'].append(features.convex_hull_perimeter(data[trial_id][track_group][track_id], pos))\n",
    "                features_dict['Fractal Dimension'].append(features.fractal_dimension(data[trial_id][track_group][track_id], pos))\n",
    "                css_mean, css_std = stats(features.curvature_scale_space(data[trial_id][track_group][track_id], pos))\n",
    "                features_dict['Curvature Scale Space (mean)'].append(css_mean)\n",
    "                features_dict['Curvature Scale Space (standard deviation)'].append(css_std)\n",
    "                c1_mean, c1_std = stats(features.curvature(data[trial_id][track_group][track_id], (0,1), time_step=(1/25)))\n",
    "                c2_mean, c2_std = stats(features.curvature(data[trial_id][track_group][track_id], (1,2), time_step=(1/25)))\n",
    "                c3_mean, c3_std = stats(features.curvature(data[trial_id][track_group][track_id], (0,2), time_step=(1/25)))\n",
    "                features_dict['Curvature X-Y (mean)'].append(c1_mean)\n",
    "                features_dict['Curvature X-Y (standard deviation)'].append(c1_std)\n",
    "                features_dict['Curvature Y-Z (mean)'].append(c2_mean)\n",
    "                features_dict['Curvature Y-Z (standard deviation)'].append(c2_std)\n",
    "                features_dict['Curvature X-Z (mean)'].append(c3_mean)\n",
    "                features_dict['Curvature X-Z (standard deviation)'].append(c3_std)\n",
    "                track_id += 1\n",
    "            track_group += 1\n",
    "        trial_id += 1\n",
    "    \n",
    "    feat_df = pd.DataFrame(data=features_dict)\n",
    "    return feat_df\n",
    "\n",
    "\n",
    "feature_columns = [\n",
    "    'X Velocity',\n",
    "    'Y Velocity',\n",
    "    'Z Velocity',\n",
    "    'Angular Velocity',\n",
    "    'Angular Velocity X-Y',\n",
    "    'Angular Velocity Y-Z',\n",
    "    'Angular Velocity X-Z',\n",
    "    'Angular Acceleration',\n",
    "    'Angular Acceleration X-Y',\n",
    "    'Angular Acceleration Y-Z',\n",
    "    'Angular Acceleration X-Z',\n",
    "    'Angle of Flight', \n",
    "    'Centroid Distance Function',\n",
    "    'Persistence Velocity',\n",
    "    'Turning Velocity',\n",
    "    'Inclination Velocity',\n",
    "    'Radial Velocity',\n",
    "    'Radial Acceleration',\n",
    "    'Radial Jerk',\n",
    "    'X Acceleration',\n",
    "    'Y Acceleration',\n",
    "    'Z Acceleration'\n",
    "]   \n",
    "\n",
    "indexes = [i for i in range(3, len(feature_columns)+3)]  \n",
    "feature_stats = ['mean','median','standard deviation', 'kurtosis', 'skewness','no of local minima','no of local maxima','no of zero-crossings', '1st quartile', '3rd quartile'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_track_statistics = dict()\n",
    "couple_track_statistics = dict()\n",
    "female_track_statistics = dict()\n",
    "focal_male_track_statistics = dict()\n",
    "\n",
    "for col in feature_columns:\n",
    "    for stat in feature_stats:\n",
    "        male_track_statistics[f'{col} ({stat})'] = []\n",
    "        couple_track_statistics[f'{col} ({stat})'] = []\n",
    "        female_track_statistics[f'{col} ({stat})'] = []\n",
    "        focal_male_track_statistics[f'{col} ({stat})'] = []\n",
    "\n",
    "\n",
    "male_track_statistics = compute_segment_statistics(male_track_statistics, males, indexes, feature_columns)\n",
    "couple_track_statistics = compute_segment_statistics(couple_track_statistics, couples, indexes, feature_columns)\n",
    "female_track_statistics = compute_segment_statistics(female_track_statistics, f_df, indexes, feature_columns)\n",
    "focal_male_track_statistics = compute_segment_statistics(focal_male_track_statistics, fm_df, indexes, feature_columns)\n",
    "\n",
    "df_males = pd.DataFrame(data=male_track_statistics)\n",
    "df_couples = pd.DataFrame(data=couple_track_statistics)\n",
    "df_f = pd.DataFrame(data=female_track_statistics)\n",
    "df_fm = pd.DataFrame(data=focal_male_track_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Add other track features'''\n",
    "\n",
    "df_males = pd.concat([df_males, add_other_features(males, (0,1,2))], axis=1)\n",
    "df_couples = pd.concat([df_couples, add_other_features(couples, (0,1,2))], axis=1)\n",
    "df_f = pd.concat([df_f, add_other_features(f_df, (0,1,2))], axis=1)\n",
    "df_fm = pd.concat([df_fm, add_other_features(fm_df, (0,1,2))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_males = remove_nans(df_males)\n",
    "df_couples = remove_nans(df_couples)\n",
    "df_f = remove_nans(df_f)\n",
    "df_fm = remove_nans(df_fm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Remove columns not in both'''\n",
    "\n",
    "similar = list(set(df_couples.columns.values) & set(df_males.columns.values) & set(df_f.columns.values) & set(df_fm.columns.values))\n",
    "df_couples = df_couples[similar]\n",
    "df_males = df_males[similar]\n",
    "df_f = df_f[similar]\n",
    "df_fm = df_fm[similar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Adding trials to Couple data for FS - test split'''\n",
    "\n",
    "def add_track_and_trial_id(df, dataset):\n",
    "    seq = []\n",
    "    track_group = []\n",
    "    count = 0\n",
    "    for trial in range(len(dataset)):\n",
    "        for group in range(len(dataset[trial])):\n",
    "            for i in range(len(dataset[trial][group])):\n",
    "                seq.append(trial)\n",
    "                track_group.append(count)\n",
    "            count += 1\n",
    "    df['seq'] = seq\n",
    "    df['track_group'] = track_group\n",
    "    return df\n",
    "\n",
    "df_males = add_track_and_trial_id(df_males, split_males)\n",
    "df_couples = add_track_and_trial_id(df_couples, split_couples)\n",
    "df_f = add_track_and_trial_id(df_f, split_females)\n",
    "df_fm = add_track_and_trial_id(df_fm, split_focal_males)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_males.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_males), len(df_couples), len(df_f), len(df_fm))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_males['track_group'].unique()), len(df_couples['track_group'].unique()), len(df_f['track_group'].unique()), len(df_fm['track_group'].unique()))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Split Couple data'''\n",
    "df_males_fs = df_males[(df_males['seq'] == 4) | (df_males['seq'] == 9) | (df_males['seq'] == 3)]\n",
    "df_males_test = df_males[~((df_males['seq'] == 4) | (df_males['seq'] == 9) | (df_males['seq'] == 3))]\n",
    "df_couple_fs = df_couples[(df_couples['seq'] == 2) | (df_couples['seq'] == 6) ].drop(columns=['seq'])\n",
    "df_couple_test = df_couples[~((df_couples['seq'] == 2) | (df_couples['seq'] == 6))].drop(columns=['seq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_males_fs), len(df_couple_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Conducting U-Test to determine whether there is any statistical difference between couples and males trajectory'''\n",
    "\n",
    "x = df_males_fs.drop(columns=['seq', 'track_group'], errors='ignore')\n",
    "y = df_couple_fs.drop(columns=['track_group'], errors='ignore')\n",
    "\n",
    "results = stats.mannwhitneyu(x, y)\n",
    "rej, pvals, a1, a2 = multipletests(results[1], alpha=0.01, method='holm')\n",
    "\n",
    "cols = {\"columns\": [], \"p_values\": [], 'raw_p':[]}\n",
    "\n",
    "for index, column in enumerate(x.columns.values):\n",
    "    if rej[index] == True:\n",
    "        cols['columns'].append(column)\n",
    "        cols['p_values'].append(pvals[index])\n",
    "        cols['raw_p'].append(results[1][index])\n",
    "\n",
    "df = pd.DataFrame(data=cols)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Removing Correlated features'''\n",
    "df_hyp = pd.concat([df_males_fs, df_couple_fs])\n",
    "\n",
    "df_hyp_sorted = df_hyp.reindex(sorted(df_hyp.columns), axis=1)\n",
    "corr_matrix = df_hyp_sorted.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.85)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Adding trial id to male df so that splitting by trial can occur'''\n",
    "\n",
    "seq = []\n",
    "for trial in range(len(split_males)):\n",
    "    for i in range(len(split_males[trial])):\n",
    "        for j in range(len(split_males[trial][i])):\n",
    "            seq.append(trial)\n",
    "\n",
    "df_males['seq'] = seq\n",
    "df_males_test = df_males.drop(index=df_males_fs.index.values)\n",
    "df_males_fs = df_males.drop(index=df_males_test.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_couple_test[cols[\"columns\"]].drop(columns=to_drop, errors='ignore').columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sorted(columns):\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Store Data'''\n",
    "\n",
    "# Store all track information (males, couples, focal-males, females)\n",
    "df_males_test.to_pickle('data/df_males_test.pkl')\n",
    "df_males_fs.to_pickle('data/df_males_fs.pkl')\n",
    "df_couple_test.to_pickle('data/df_couples_test.pkl')\n",
    "df_couple_fs.to_pickle('data/df_couples_fs.pkl')\n",
    "df_f.to_pickle('data/df_females.pkl')\n",
    "df_fm.to_pickle('data/df_focal_males.pkl')\n",
    "\n",
    "\n",
    "np.save('data/males.npy', males)\n",
    "np.save('data/couple.npy', couples)\n",
    "np.save('data/f_df.npy', f_df)\n",
    "np.save('data/fm_df.npy', fm_df)\n",
    "\n",
    "# Store p-values\n",
    "np.save('data/non_adj_pvals.npy', results[1])\n",
    "np.save('data/all_pvals.npy', pvals)\n",
    "df.to_pickle('data/selected_pvals.pkl')\n",
    "\n",
    "# Store selected columns\n",
    "columns = df_couple_test[cols[\"columns\"]].drop(columns=to_drop, errors='ignore').columns.values\n",
    "np.save('data/columns.npy', columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Load Data'''\n",
    "\n",
    "df_males_test = pd.read_pickle('data/df_males_test.pkl')\n",
    "df_males_fs = pd.read_pickle('data/df_males_fs.pkl')\n",
    "df_couple_test = pd.read_pickle('data/df_couples_test.pkl')\n",
    "df_couple_fs = pd.read_pickle('data/df_couples_fs.pkl')\n",
    "df_f = pd.read_pickle('data/df_females.pkl')\n",
    "df_fm = pd.read_pickle('data/df_focal_males.pkl')\n",
    "\n",
    "males = np.load('data/males.npy', allow_pickle=True)\n",
    "couples = np.load('data/couple.npy', allow_pickle=True)\n",
    "f_df = np.load('data/f_df.npy', allow_pickle=True)\n",
    "fm_df = np.load('data/fm_df.npy', allow_pickle=True)\n",
    "\n",
    "df_males = pd.concat([df_males_fs, df_males_test])\n",
    "df_couples = pd.concat([df_couple_test, df_couple_fs])\n",
    "\n",
    "columns = np.load('data/columns.npy', allow_pickle=True)\n",
    "pvals = pd.read_pickle('data/selected_pvals.pkl')\n",
    "non_adj_pvals = np.load('data/non_adj_pvals.npy', allow_pickle=True)\n",
    "all_pvals = np.load('data/all_pvals.npy', allow_pickle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logistic_array(arr):\n",
    "    return [1/(1 + np.exp(-x)) for x in arr]\n",
    "\n",
    "def get_mode(_set, predicts, decisions):\n",
    "    predictions = []\n",
    "    avg_decision = []\n",
    "    unique_track_groups = _set.unique()\n",
    "    for val in unique_track_groups:\n",
    "        indexes = np.where(_set == val)\n",
    "        preds = predicts[indexes]\n",
    "        avg_decision.append(np.mean(decisions[indexes]))\n",
    "        preds = np.array(np.sign(np.mean(decisions[indexes])))\n",
    "        preds[preds == 0] = 1\n",
    "        predictions.append(preds)\n",
    "    return predictions, avg_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "CROSS VALIDATION \n",
    "'''\n",
    "all_trials = df_males_test['seq'].unique()\n",
    "\n",
    "male_train_predictions = {'predictions': [], 'accuracy': []}\n",
    "male_test_predictions = {'predictions': [], 'accuracy': []}\n",
    "couple_predictions = {'predictions': [],  'accuracy': []}\n",
    "female_predictions = {'predictions': [], 'accuracy': []}\n",
    "focal_male_predictions = {'predictions': [], 'accuracy': []}\n",
    "all_test_predictions = {\n",
    "    'true': [], 'preds': [],\n",
    "    'accuracy': [], 'roc auc':[], \n",
    "    'f1 score (male)':[], 'recall (male)':[], 'precision (male)':[], \n",
    "    'f1 score (non-male)':[], 'recall (non-male)':[], 'precision (non-male)':[],\n",
    "    'f1 score (avg)':[], 'recall (avg)':[], 'precision (avg)':[], }\n",
    "roc_curve = {'fpr': [], 'tpr': []}\n",
    "pr_curve = {'m_precision': [], 'm_recall': [], 'm_auc':[], 'm_pn':[], 'n_precision': [], 'n_recall': [], 'n_auc':[], 'n_pn':[], 'auc':[]}\n",
    "\n",
    "shap_train = []\n",
    "shap_test = []\n",
    "\n",
    "seq_test = []\n",
    "seq_train = []\n",
    "\n",
    "nu = 0.2\n",
    "kernel = 'rbf'\n",
    "gamma = (1/len(columns))**2\n",
    "degree = 3\n",
    "\n",
    "a1 = all_trials\n",
    "a2 = all_trials\n",
    "for val1 in tqdm.tqdm(a1):\n",
    "    a2 = a2[a2 != val1]\n",
    "    for val2 in a2:\n",
    "        if val1 != val2:\n",
    "            #print(f' ----- {val1} - {val2} ----')\n",
    "            train = df_males_test[~((df_males_test['seq'] == val1) | (df_males_test['seq'] == val2))]\n",
    "            test = df_males_test[((df_males_test['seq'] == val1) | (df_males_test['seq'] == val2))]\n",
    "\n",
    "            seq_test.append([val1, val2])\n",
    "            seq_train.append([x for x in all_trials if x not in [val1, val2]])\n",
    "    \n",
    "            scaler = StandardScaler()\n",
    "            train_standard = scaler.fit_transform(train[columns])\n",
    "            train_standard = pd.DataFrame(train_standard, index=train.index, columns=columns)\n",
    "\n",
    "            test_standard = scaler.transform(test[columns])\n",
    "            test_standard = pd.DataFrame(test_standard, index=test.index, columns=columns)\n",
    "\n",
    "            df_couple_test_standard = scaler.transform(df_couple_test[columns])\n",
    "            df_couple_test_standard = pd.DataFrame(df_couple_test_standard, index=df_couple_test.index, columns=columns)\n",
    "\n",
    "            df_f_scaler = scaler.transform(df_f[columns])\n",
    "            df_f_scaler = pd.DataFrame(df_f_scaler, index=df_f.index, columns=columns)\n",
    "\n",
    "            focal_male_standard = scaler.transform(df_fm[columns])\n",
    "            focal_male_standard = pd.DataFrame(focal_male_standard, index=df_fm.index, columns=columns)\n",
    "\n",
    "            clf = OneClassSVM(\n",
    "                nu=nu,\n",
    "                kernel=kernel,\n",
    "                gamma=gamma,\n",
    "                degree=degree\n",
    "            ).fit(train_standard)\n",
    "\n",
    "            # ---------- TRAIN SET ---------- \n",
    "            male_train_predictions['predictions'].append(clf.predict(train_standard))\n",
    "            preds, scores = get_mode(train['track_group'], clf.predict(train_standard), clf.decision_function(train_standard))\n",
    "            male_train_predictions['accuracy'].append(metrics.accuracy_score([1 for l in range(len(preds))], preds))\n",
    "\n",
    "            # ---------- TEST SET ---------- \n",
    "            male_test_predictions['predictions'].append(clf.predict(test_standard))\n",
    "            preds, scores = get_mode(test['track_group'], clf.predict(test_standard), clf.decision_function(test_standard))\n",
    "            male_test_predictions['accuracy'].append(metrics.accuracy_score([1 for l in range(len(preds))], preds))\n",
    "\n",
    "            # ---------- COUPLE SET ---------- \n",
    "            couple_predictions['predictions'].append(clf.predict(df_couple_test_standard))\n",
    "            preds, scores = get_mode(df_couple_test['track_group'], clf.predict(df_couple_test_standard), clf.decision_function(df_couple_test_standard))\n",
    "            couple_predictions['accuracy'].append(metrics.accuracy_score([-1 for l in range(len(preds))], preds))\n",
    "\n",
    "            # ---------- FEMALE SET ---------- \n",
    "            female_predictions['predictions'].append(clf.predict(df_f_scaler))\n",
    "            preds, scores = get_mode(df_f['track_group'], clf.predict(df_f_scaler), clf.decision_function(df_f_scaler))\n",
    "            female_predictions['accuracy'].append(metrics.accuracy_score([-1 for l in range(len(preds))], preds))\n",
    "\n",
    "            # ---------- FOCAL MALE SET ---------- \n",
    "            focal_male_predictions['predictions'].append(clf.predict(focal_male_standard))\n",
    "            preds, scores = get_mode(df_fm['track_group'], clf.predict(focal_male_standard), clf.decision_function(focal_male_standard))\n",
    "            focal_male_predictions['accuracy'].append(metrics.accuracy_score([1 for l in range(len(preds))], preds))\n",
    "\n",
    "            # ------------ ALL TEST SET ------------\n",
    "            full_test_set = pd.concat([test[columns], df_couple_test[columns], df_f[columns], df_fm[columns]])\n",
    "            full_test_set_scaled = scaler.transform(full_test_set)\n",
    "            full_test_set = pd.DataFrame(full_test_set_scaled, index=full_test_set.index, columns=full_test_set.columns)\n",
    "            full_test_groups = pd.concat([\n",
    "                test['track_group'].apply(lambda row: f'm{row}'),\n",
    "                df_couple_test['track_group'].apply(lambda row: f'c{row}'),\n",
    "                df_f['track_group'].apply(lambda row: f'f{row}'),\n",
    "                df_fm['track_group'].apply(lambda row: f'fm{row}')])\n",
    "\n",
    "            all_track_targets = [1 for _ in range(len(test['track_group'].unique()))] + [-1 for _ in range(len(df_couple_test['track_group'].unique()))] + [-1 for _ in range(len(df_f['track_group'].unique()))] + [1 for _ in range(len(df_fm['track_group'].unique()))]\n",
    "\n",
    "            preds, scores = get_mode(\n",
    "                full_test_groups,\n",
    "                clf.predict(full_test_set), \n",
    "                clf.decision_function(full_test_set), \n",
    "            )\n",
    "            all_test_predictions['true'].append(all_track_targets)\n",
    "            all_test_predictions['preds'].append(preds)\n",
    "\n",
    "            all_test_predictions['accuracy'].append(metrics.balanced_accuracy_score(all_track_targets, preds))\n",
    "            all_test_predictions['roc auc'].append(metrics.roc_auc_score(np.array(all_track_targets), compute_logistic_array(np.array(scores))))\n",
    "\n",
    "            all_test_predictions['f1 score (male)'].append(metrics.f1_score(all_track_targets, preds))\n",
    "            all_test_predictions['recall (male)'].append(metrics.recall_score(all_track_targets, preds))\n",
    "            all_test_predictions['precision (male)'].append(metrics.precision_score(all_track_targets, preds))\n",
    "\n",
    "            all_test_predictions['f1 score (non-male)'].append(metrics.f1_score(all_track_targets, preds, pos_label=-1))\n",
    "            all_test_predictions['recall (non-male)'].append(metrics.recall_score(all_track_targets, preds, pos_label=-1))\n",
    "            all_test_predictions['precision (non-male)'].append(metrics.precision_score(all_track_targets, preds, pos_label=-1))\n",
    "            \n",
    "            all_test_predictions['f1 score (avg)'].append((all_test_predictions['f1 score (male)'][-1] + all_test_predictions['f1 score (non-male)'][-1])/2)\n",
    "            all_test_predictions['recall (avg)'].append((all_test_predictions['recall (male)'][-1] + all_test_predictions['recall (non-male)'][-1])/2)\n",
    "            all_test_predictions['precision (avg)'].append((all_test_predictions['precision (male)'][-1] + all_test_predictions['precision (non-male)'][-1])/2)\n",
    "\n",
    "            fpr, tpr, _ = metrics.roc_curve(np.array(all_track_targets), compute_logistic_array(scores))\n",
    "            roc_curve['fpr'].append(fpr)\n",
    "            roc_curve['tpr'].append(tpr)\n",
    "\n",
    "            shap_train.append(train_standard)\n",
    "            shap_test.append(full_test_set)\n",
    "\n",
    "            precision, recall, thresholds = metrics.precision_recall_curve(all_track_targets, compute_logistic_array(scores))\n",
    "            pr_curve['m_precision'].append(precision)\n",
    "            pr_curve['m_recall'].append(recall)\n",
    "            pr_curve['m_auc'].append(metrics.auc(recall, precision))\n",
    "            pr_curve['m_pn'].append(len([i for i in all_track_targets if i == 1])/len(all_track_targets))\n",
    "\n",
    "            precision, recall, thresholds = metrics.precision_recall_curve(np.array(all_track_targets)*-1, [1 - ar for ar in compute_logistic_array(np.array(scores))])\n",
    "            pr_curve['n_precision'].append(precision)\n",
    "            pr_curve['n_recall'].append(recall)\n",
    "            pr_curve['n_auc'].append(metrics.auc(recall, precision))\n",
    "            pr_curve['n_pn'].append(len([i for i in np.array(all_track_targets) if i == -1])/len(all_track_targets))\n",
    "\n",
    "            pr_curve['auc'].append((pr_curve['m_auc'][-1] + pr_curve['n_auc'][-1])/2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shap_train.npy', np.array(shap_train))\n",
    "np.save('shap_test.npy', np.array(shap_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(' -- TRAIN SET (MALES) --')\n",
    "print(f'Accuracy: {round(sum(male_train_predictions[\"accuracy\"])/len(male_train_predictions[\"accuracy\"]), 3)} ({round(np.percentile(male_train_predictions[\"accuracy\"], 2.5), 3)} - {round(np.percentile(male_train_predictions[\"accuracy\"], 97.5), 3)})')\n",
    "print('\\n -- TEST SET (MALES) --')\n",
    "print(f'Accuracy: {round(sum(male_test_predictions[\"accuracy\"])/len(male_test_predictions[\"accuracy\"]), 3)} ({round(np.percentile(male_test_predictions[\"accuracy\"], 2.5), 3)} - {round(np.percentile(male_test_predictions[\"accuracy\"], 97.5), 3)})')\n",
    "print('\\n -- COUPLES --')\n",
    "print(f'Accuracy: {round(sum(couple_predictions[\"accuracy\"])/len(couple_predictions[\"accuracy\"]), 3)} ({round(np.percentile(couple_predictions[\"accuracy\"], 2.5), 3)} - {round(np.percentile(couple_predictions[\"accuracy\"], 97.5), 3)})')\n",
    "print('\\n -- FEMALES -- ')\n",
    "print(f'Accuracy: {round(sum(female_predictions[\"accuracy\"])/len(female_predictions[\"accuracy\"]), 3)} ({round(np.percentile(female_predictions[\"accuracy\"], 2.5), 3)} - {round(np.percentile(female_predictions[\"accuracy\"], 97.5), 3)})')\n",
    "print('\\n -- FOCAL MALES -- ')\n",
    "print(f'Accuracy: {round(sum(focal_male_predictions[\"accuracy\"])/len(focal_male_predictions[\"accuracy\"]), 3)} ({round(np.percentile(focal_male_predictions[\"accuracy\"], 2.5), 3)} - {round(np.percentile(focal_male_predictions[\"accuracy\"], 97.5), 3)})')\n",
    "\n",
    "print('\\n -- TOTAL DATASET --')\n",
    "print(f'BALANCED ACCURACY: {round(sum(all_test_predictions[\"accuracy\"])/len(all_test_predictions[\"accuracy\"]), 3)} ({round(np.percentile(all_test_predictions[\"accuracy\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"accuracy\"], 97.5), 3)})')\n",
    "print(f'ROC AUC: {round(sum(all_test_predictions[\"roc auc\"])/len(all_test_predictions[\"roc auc\"]), 3)} ({round(np.percentile(all_test_predictions[\"roc auc\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"roc auc\"], 97.5), 3)})')\n",
    "\n",
    "print(f'\\nF1 SCORE (avg): {round(sum(all_test_predictions[\"f1 score (avg)\"])/len(all_test_predictions[\"f1 score (avg)\"]), 3)} ({round(np.percentile(all_test_predictions[\"f1 score (avg)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"f1 score (avg)\"], 97.5), 3)})')\n",
    "print(f'F1 SCORE (male): {round(sum(all_test_predictions[\"f1 score (male)\"])/len(all_test_predictions[\"f1 score (male)\"]), 3)} ({round(np.percentile(all_test_predictions[\"f1 score (male)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"f1 score (male)\"], 97.5), 3)})')\n",
    "print(f'F1 SCORE (non-male): {round(sum(all_test_predictions[\"f1 score (non-male)\"])/len(all_test_predictions[\"f1 score (non-male)\"]), 3)} ({round(np.percentile(all_test_predictions[\"f1 score (non-male)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"f1 score (non-male)\"], 97.5), 3)})')\n",
    "\n",
    "print(f'\\nRECALL (avg): {round(sum(all_test_predictions[\"recall (avg)\"])/len(all_test_predictions[\"recall (avg)\"]), 3)} ({round(np.percentile(all_test_predictions[\"recall (avg)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"recall (avg)\"], 97.5), 3)})')\n",
    "print(f'RECALL (male): {round(sum(all_test_predictions[\"recall (male)\"])/len(all_test_predictions[\"recall (male)\"]), 3)} ({round(np.percentile(all_test_predictions[\"recall (male)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"recall (male)\"], 97.5), 3)})')\n",
    "print(f'RECALL (non-male): {round(sum(all_test_predictions[\"recall (non-male)\"])/len(all_test_predictions[\"recall (non-male)\"]), 3)} ({round(np.percentile(all_test_predictions[\"recall (non-male)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"recall (non-male)\"], 97.5), 3)})')\n",
    "\n",
    "print(f'\\nPRECISION (avg): {round(sum(all_test_predictions[\"precision (avg)\"])/len(all_test_predictions[\"precision (avg)\"]), 3)} ({round(np.percentile(all_test_predictions[\"precision (avg)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"precision (avg)\"], 97.5), 3)})')\n",
    "print(f'PRECISION (male): {round(sum(all_test_predictions[\"precision (male)\"])/len(all_test_predictions[\"precision (male)\"]), 3)} ({round(np.percentile(all_test_predictions[\"precision (male)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"precision (male)\"], 97.5), 3)})')\n",
    "print(f'PRECISION (non-male): {round(sum(all_test_predictions[\"precision (non-male)\"])/len(all_test_predictions[\"precision (non-male)\"]), 3)} ({round(np.percentile(all_test_predictions[\"precision (non-male)\"], 2.5), 3)} - {round(np.percentile(all_test_predictions[\"precision (non-male)\"], 97.5), 3)})')\n",
    "\n",
    "print(f'\\nPR AUC (avg): {round(sum(pr_curve[\"auc\"])/len(pr_curve[\"auc\"]), 3)} ({round(np.percentile(pr_curve[\"auc\"], 2.5), 3)} - {round(np.percentile(pr_curve[\"auc\"], 97.5), 3)})')\n",
    "print(f'PR AUC (male): {round(sum(pr_curve[\"m_auc\"])/len(pr_curve[\"m_auc\"]), 3)} ({round(np.percentile(pr_curve[\"m_auc\"], 2.5), 3)} - {round(np.percentile(pr_curve[\"m_auc\"], 97.5), 3)})')\n",
    "print(f'PR AUC (non-male): {round(sum(pr_curve[\"n_auc\"])/len(pr_curve[\"n_auc\"]), 3)} ({round(np.percentile(pr_curve[\"n_auc\"], 2.5), 3)} - {round(np.percentile(pr_curve[\"n_auc\"], 97.5), 3)})')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "HYPERPARAMETER TUNING\n",
    "'''\n",
    "\n",
    "data = {'nu':[], 'kernel':[], 'gamma':[], 'degree':[], 'accuracy': [], 'roc auc':[]}\n",
    "all_trials = df_males_fs['seq'].unique()\n",
    "\n",
    "for nu in tqdm.tqdm([i/100 for i in range(1, 40, 1)]):\n",
    "    for kernel in ['rbf']:\n",
    "        for degree in [3]:\n",
    "            for gamma in ['scale', 'auto', 1/(len(columns)**2)]:\n",
    "                a1 = all_trials\n",
    "                a2 = all_trials\n",
    "                accuracy_vals = []\n",
    "                roc_auc_vals = []\n",
    "\n",
    "                for val1 in a1:\n",
    "                    a2 = a2[a2 != val1]\n",
    "                    for val2 in a2:\n",
    "                        if val1 != val2:\n",
    "                            train = df_males_fs[((df_males_fs['seq'] == val1) | (df_males_fs['seq'] == val2))]\n",
    "                            test = df_males_fs[~((df_males_fs['seq'] == val1) | (df_males_fs['seq'] == val2))]\n",
    "\n",
    "                            scaler = StandardScaler()\n",
    "                            train_standard = scaler.fit_transform(train[columns])\n",
    "                            train_standard = pd.DataFrame(train_standard, columns=columns, index=train.index)\n",
    "\n",
    "                            clf = OneClassSVM(\n",
    "                                nu=nu,\n",
    "                                kernel=kernel,\n",
    "                                degree=degree, \n",
    "                                gamma=gamma\n",
    "                            ).fit(train_standard)\n",
    "\n",
    "                            # ------------ ALL TEST SET ------------\n",
    "                            full_test = pd.concat([test[columns], df_couple_fs[columns]])\n",
    "                            full_test_set = scaler.transform(full_test)\n",
    "                            full_test_set = pd.DataFrame(full_test_set, index=full_test.index, columns=columns)\n",
    "                            full_test_groups = pd.concat([\n",
    "                                test['track_group'].apply(lambda row: f'm{row}'),\n",
    "                                df_couple_fs['track_group'].apply(lambda row: f'c{row}')])\n",
    "\n",
    "                            all_track_targets = [1 for _ in range(len(test['track_group'].unique()))] + [-1 for _ in range(len(df_couple_fs['track_group'].unique()))] \n",
    "\n",
    "                            preds, scores = get_mode(\n",
    "                                full_test_groups,\n",
    "                                clf.predict(full_test_set), \n",
    "                                clf.decision_function(full_test_set), \n",
    "                            )\n",
    "                            accuracy_vals.append(metrics.balanced_accuracy_score(all_track_targets, preds))\n",
    "                            roc_auc_vals.append(metrics.roc_auc_score(np.array(all_track_targets), compute_logistic_array(np.array(scores))))\n",
    "\n",
    "                data['nu'].append(nu)\n",
    "                data['kernel'].append(kernel)\n",
    "                data['degree'].append(degree)\n",
    "                data['gamma'].append(gamma)\n",
    "                data['accuracy'].append(np.mean(accuracy_vals))\n",
    "                data['roc auc'].append(np.mean(roc_auc_vals))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_df.to_pickle('hyp_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_df = pd.read_pickle('results/tuned and standardised/hyp_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = hyp_df.sort_values(by='accuracy').iloc[-1]['accuracy']\n",
    "hyp_df[(hyp_df['accuracy'] == best_acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp_df.sort_values(by='accuracy')[-20:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''EXCEL FILE OF ALL FOLD SCORES'''\n",
    "\n",
    "import openpyxl\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "sheet = wb.create_sheet()\n",
    "\n",
    "cols = ['fold', 'test trials', 'train trials', 'accuracy (male train)', 'accuracy (male test)',\n",
    "    'accuracy (couple test)', 'balanced accuracy (all)', 'roc auc (all)']\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    sheet.cell(row=1, column=i+1).value = col\n",
    "\n",
    "\n",
    "for fold in range(len(all_test_predictions['accuracy'])):\n",
    "    sheet.cell(row=fold+2, column=1).value = fold\n",
    "    sheet.cell(row=fold+2, column=2).value = str(seq_test[fold])\n",
    "    sheet.cell(row=fold+2, column=3).value = str(seq_train[fold])\n",
    "    sheet.cell(row=fold+2, column=4).value = male_train_predictions['accuracy'][fold]\n",
    "    sheet.cell(row=fold+2, column=5).value = male_test_predictions['accuracy'][fold]\n",
    "    sheet.cell(row=fold+2, column=6).value = couple_predictions['accuracy'][fold]\n",
    "    sheet.cell(row=fold+2, column=7).value = all_test_predictions['accuracy'][fold]\n",
    "    sheet.cell(row=fold+2, column=8).value = all_test_predictions['roc auc'][fold]\n",
    "\n",
    "wb.save(\"all-folds.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix as con_mat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "\n",
    "y_test =  list(chain.from_iterable(all_test_predictions['true']))\n",
    "y_pred =  list(chain.from_iterable(all_test_predictions['preds']))\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "plt.figure(figsize=(8, 6), dpi=400)\n",
    "con = con_mat(y_test, y_pred)\n",
    "cmap = sns.light_palette(\"#dd7301\", as_cmap=True)\n",
    "sns.heatmap(con, annot=True, cmap=cmap, fmt=\".1f\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"True Class\")\n",
    "plt.xticks([0.5,1.5], ['Non-Male', 'Male'])\n",
    "plt.yticks([0.5,1.5], ['Non-Male', 'Male'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''ROC Curve'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=400)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "lw = 2\n",
    "tprs = []\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "for index in range(len(roc_curve['tpr'])):\n",
    "    plt.plot(\n",
    "        roc_curve['fpr'][index],\n",
    "        roc_curve['tpr'][index],\n",
    "        color=\"blue\",\n",
    "        alpha=0.15,\n",
    "        lw=lw,\n",
    "    )\n",
    "    tpr = np.interp(base_fpr, roc_curve['fpr'][index], roc_curve['tpr'][index])\n",
    "    tpr[0] = 0.0\n",
    "    tprs.append(tpr)\n",
    "\n",
    "tprs = np.array(tprs)\n",
    "mean_tprs = tprs.mean(axis=0)\n",
    "std = tprs.std(axis=0)\n",
    "\n",
    "tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "tprs_lower = mean_tprs - std\n",
    "\n",
    "\n",
    "plt.plot(base_fpr, mean_tprs, 'b')\n",
    "plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"black\", lw=lw, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "#plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=400)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "lw = 2\n",
    "tprs = []\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "line_type = ['-', '--', '-.']\n",
    "colours = ['blue', 'green']\n",
    "\n",
    "best = 1\n",
    "worst = 22\n",
    "\n",
    "for i, index in enumerate([best, worst]):\n",
    "    plt.plot(\n",
    "        pr_curve['m_recall'][index],\n",
    "        pr_curve['m_precision'][index],\n",
    "        color=colours[i],\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.plot(\n",
    "        base_fpr,\n",
    "        [pr_curve['m_pn'][index] for i in base_fpr],\n",
    "        color=colours[i],\n",
    "        alpha=0.4,\n",
    "        linestyle='--'\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.legend([f'Best fold (AUC = {round(pr_curve[\"m_auc\"][best], 3)})', f'Best fold baseline (AUC = {round(pr_curve[\"m_pn\"][best], 3)})', f'Worst fold (AUC = {round(pr_curve[\"m_auc\"][worst], 3)}', f'Worst fold baseline (AUC = {round(pr_curve[\"m_pn\"][worst], 3)})'])\n",
    "plt.title(f\"Precision-Recall (PR) Curve (male)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,10), dpi=400)\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "lw = 2\n",
    "tprs = []\n",
    "base_fpr = np.linspace(0, 1, 101)\n",
    "\n",
    "line_type = ['-', '--', '-.']\n",
    "colours = ['blue', 'green']\n",
    "\n",
    "best = 1\n",
    "worst = 22\n",
    "\n",
    "for i, index in enumerate([best, worst]):\n",
    "    plt.plot(\n",
    "        pr_curve['n_recall'][index],\n",
    "        pr_curve['n_precision'][index],\n",
    "        color=colours[i],\n",
    "        lw=lw,\n",
    "    )\n",
    "    plt.plot(\n",
    "        base_fpr,\n",
    "        [pr_curve['n_pn'][index] for i in base_fpr],\n",
    "        color=colours[i],\n",
    "        alpha=0.4,\n",
    "        linestyle='--'\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlim((0,1))\n",
    "plt.ylim((0,1))\n",
    "plt.legend([f'Best fold (AUC = {round(pr_curve[\"n_auc\"][best], 3)})', f'Best fold baseline (AUC = {round(pr_curve[\"n_pn\"][best], 3)})', f'Worst fold (AUC = {round(pr_curve[\"n_auc\"][worst], 3)}', f'Worst fold baseline (AUC = {round(pr_curve[\"n_pn\"][worst], 3)})'])\n",
    "plt.title(\"Precision-Recall (PR) Curve (non-male)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "0af35ced4013b40c48ef8bea2bd8893a84400903cabc48180593f96176f9d4b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
